{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T16:22:48.189595Z",
     "start_time": "2024-06-06T16:22:40.958798Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable detailed CUDA error reporting\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Define MTAD-GAT model with GRU layer\n",
    "class MTADGAT(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_heads):\n",
    "        super(MTADGAT, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=num_heads, concat=True)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, output_dim, heads=1, concat=True)\n",
    "        self.gru = nn.GRU(output_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = x.view(1, -1, x.size(1))  # Reshape for GRU\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.fc(x.view(-1, x.size(2)))\n",
    "        return x\n",
    "\n",
    "# Load data function\n",
    "def load_data(files):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        df.drop(columns=['time'], inplace=True)  # 'time' column removal\n",
    "        df_list.append(df)\n",
    "    combined_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# File paths\n",
    "train_files = [\n",
    "    'C:/Users/Researcher/Desktop/MTAD-GAT/train/train1.csv',\n",
    "    'C:/Users/Researcher/Desktop/MTAD-GAT/train/train2.csv'\n",
    "]\n",
    "test_files = [\n",
    "    'C:/Users/Researcher/Desktop/MTAD-GAT/test1/test1.csv',\n",
    "    'C:/Users/Researcher/Desktop/MTAD-GAT/test1/test2.csv'\n",
    "]\n",
    "\n",
    "# Load data\n",
    "train_df = load_data(train_files)\n",
    "test_df = load_data(test_files)\n",
    "\n",
    "# Data preparation function\n",
    "def prepare_data(df, label_column='attack'):\n",
    "    inputs = df.drop(columns=[label_column]).values.astype(float)\n",
    "    labels = df[label_column].values.astype(float)\n",
    "    return torch.tensor(inputs, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Data preprocessing\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_df.drop(columns=['attack']))\n",
    "test_scaled = scaler.transform(test_df.drop(columns=['attack']))\n",
    "\n",
    "train_scaled_df = pd.DataFrame(train_scaled, columns=train_df.columns.drop('attack'))\n",
    "test_scaled_df = pd.DataFrame(test_scaled, columns=test_df.columns.drop('attack'))\n",
    "\n",
    "train_scaled_df['attack'] = train_df['attack'].values\n",
    "test_scaled_df['attack'] = test_df['attack'].values\n",
    "\n",
    "train_inputs, train_labels = prepare_data(train_scaled_df, label_column='attack')\n",
    "test_inputs, test_labels = prepare_data(test_scaled_df, label_column='attack')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_inputs, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputs, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Function to create edge_index based on correlation matrix\n",
    "def create_edge_index(corr_matrix, threshold=0.5):\n",
    "    edge_index = []\n",
    "    num_nodes = corr_matrix.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j and abs(corr_matrix[i, j]) >= threshold:\n",
    "                edge_index.append([i, j])\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = train_scaled_df.drop(columns=['attack']).corr().values\n",
    "\n",
    "# Create edge_index\n",
    "num_nodes = train_scaled_df.drop(columns=['attack']).shape[1]\n",
    "edge_index = create_edge_index(corr_matrix, threshold=0.5)\n",
    "\n",
    "# Model initialization and training setup\n",
    "input_dim = num_nodes  # Input dimension\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "num_heads = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MTADGAT(input_dim, hidden_dim, output_dim, num_heads)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model training\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Check the shapes and values\n",
    "        assert inputs.size(0) == labels.size(0), f\"Batch size mismatch: {inputs.size(0)} vs {labels.size(0)}\"\n",
    "        assert not torch.any(torch.isnan(inputs)), \"NaNs found in inputs\"\n",
    "        assert not torch.any(torch.isnan(labels)), \"NaNs found in labels\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, edge_index.to(device))\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'model_checkpoint_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Model evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs, edge_index.to(device))\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = np.mean((test_labels.numpy() - predictions.flatten()) ** 2)\n",
    "mae = mean_absolute_error(test_labels.numpy(), predictions)\n",
    "r2 = r2_score(test_labels.numpy(), predictions)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Anomaly detection\n",
    "anomaly_threshold = mse + 3 * np.std(predictions - test_labels.numpy().reshape(-1, 1))\n",
    "\n",
    "anomalies = (np.abs(predictions - test_labels.numpy().reshape(-1, 1)) > anomaly_threshold).astype(int)\n",
    "\n",
    "# Classification metrics\n",
    "accuracy = accuracy_score(test_labels.numpy(), anomalies)\n",
    "f1 = f1_score(test_labels.numpy(), anomalies, average='macro')\n",
    "cm = confusion_matrix(test_labels.numpy(), anomalies)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualization of predictions and anomalies\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(test_labels.numpy(), label='Actual', color='blue')\n",
    "plt.plot(predictions, label='Predicted', color='green')\n",
    "plt.scatter(np.where(anomalies == 1)[0], predictions[anomalies == 1], color='red', label='Anomalies')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 112\u001B[0m\n\u001B[0;32m    109\u001B[0m model \u001B[38;5;241m=\u001B[39m MTADGAT(input_dim, hidden_dim, output_dim, num_heads)\n\u001B[0;32m    111\u001B[0m \u001B[38;5;66;03m# Move model to GPU\u001B[39;00m\n\u001B[1;32m--> 112\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    114\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[0;32m    115\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1170\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1171\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(convert)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m fn(param)\n\u001B[0;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1153\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1154\u001B[0m             device,\n\u001B[0;32m   1155\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1156\u001B[0m             non_blocking,\n\u001B[0;32m   1157\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1158\u001B[0m         )\n\u001B[1;32m-> 1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1160\u001B[0m         device,\n\u001B[0;32m   1161\u001B[0m         dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1162\u001B[0m         non_blocking,\n\u001B[0;32m   1163\u001B[0m     )\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
